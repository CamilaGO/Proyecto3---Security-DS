{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROYECTO 3 - Security Data Science\n",
    "### Parte 2 - Ataque de evasiÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\art\\estimators\\certification\\__init__.py:12: UserWarning: PyTorch not found. Not importing DeepZ functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ functionality\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from math import log\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from art.estimators.classification import KerasClassifier\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Rescaling, InputLayer, Reshape\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "import tensorflow as tf\n",
    "from art.attacks import ExtractionAttack\n",
    "from art.attacks.extraction import CopycatCNN, KnockoffNets\n",
    "from art.defences.postprocessor import ReverseSigmoid\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.attacks.evasion import BasicIterativeMethod\n",
    "from art.defences.trainer import AdversarialTrainer\n",
    "from art.estimators.classification import TensorFlowV2Classifier\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir aqui el path de la carpeta con imagenes. Usar doble \\\\ para el path\n",
    "path_root = \"D:\\\\UVG\\\\9noSemestre\\\\SecurityDataScience\\\\Proyecto3---Security-DS\\\\malimg_dataset\\\\malimg_paper_dataset_imgs\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9339 images belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = ImageDataGenerator().flow_from_directory(directory = path_root, target_size = (64, 64), batch_size = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos next() para recorrer todos los elementos y generar un batch de imagenes y label del data set\n",
    "imgs, labels = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9339, 64, 64, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nuestras imagenes estan en RGB con formato 64x64 [width x length x depth].\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y prueba\n",
    "Se divide la data en 55% train y 45% test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test0, y_train, y_test0 = train_test_split(imgs, labels, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7938, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7938, 25)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2, 21, ...,  2,  2, 13], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_new = np.argmax(y_train, axis=1) # se extraen solo las clases\n",
    "y_train_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.executing_eagerly():\n",
    "    tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 25 # se especifica la cantidad de clases de imagenes para clasificar\n",
    "\n",
    "def get_original_model():\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=(64, 64,3)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'adam', \n",
    "            metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = get_original_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling (Rescaling)       (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 25)                3225      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,628,377\n",
      "Trainable params: 1,628,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "original_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7938 samples, validate on 1401 samples\n",
      "Epoch 1/5\n",
      "7930/7938 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.8607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7938/7938 [==============================] - 24s 3ms/sample - loss: 0.4891 - accuracy: 0.8608 - val_loss: 0.1373 - val_accuracy: 0.9529\n",
      "Epoch 2/5\n",
      "7938/7938 [==============================] - 23s 3ms/sample - loss: 0.1240 - accuracy: 0.9631 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
      "Epoch 3/5\n",
      "7938/7938 [==============================] - 23s 3ms/sample - loss: 0.0815 - accuracy: 0.9747 - val_loss: 0.1174 - val_accuracy: 0.9650\n",
      "Epoch 4/5\n",
      "7938/7938 [==============================] - 23s 3ms/sample - loss: 0.0616 - accuracy: 0.9809 - val_loss: 0.1054 - val_accuracy: 0.9679\n",
      "Epoch 5/5\n",
      "7938/7938 [==============================] - 22s 3ms/sample - loss: 0.0664 - accuracy: 0.9795 - val_loss: 0.1099 - val_accuracy: 0.9679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffd64d96d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.fit(X_train, y_train, batch_size=10, validation_data=(X_test0, y_test0), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo robusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_robust():\n",
    "    model = Sequential()\n",
    "    model.add(Rescaling(1./255, input_shape=(64,64,3)))\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer = 'adam', \n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_robust = get_model_robust() # se crea el modelo con capas mas densas, es decir un modelo mas pro para mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 12544)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1024)              12846080  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                25625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,891,097\n",
      "Trainable params: 12,891,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_robust.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7938 samples, validate on 1401 samples\n",
      "Epoch 1/5\n",
      "7938/7938 [==============================] - 71s 9ms/sample - loss: 0.5706 - accuracy: 0.8332 - val_loss: 0.2300 - val_accuracy: 0.9158\n",
      "Epoch 2/5\n",
      "7938/7938 [==============================] - 71s 9ms/sample - loss: 0.1467 - accuracy: 0.9545 - val_loss: 0.1559 - val_accuracy: 0.9593\n",
      "Epoch 3/5\n",
      "7938/7938 [==============================] - 74s 9ms/sample - loss: 0.0983 - accuracy: 0.9679 - val_loss: 0.1390 - val_accuracy: 0.9536\n",
      "Epoch 4/5\n",
      "7938/7938 [==============================] - 73s 9ms/sample - loss: 0.0728 - accuracy: 0.9769 - val_loss: 0.0959 - val_accuracy: 0.9622\n",
      "Epoch 5/5\n",
      "7938/7938 [==============================] - 75s 9ms/sample - loss: 0.0788 - accuracy: 0.9798 - val_loss: 0.1619 - val_accuracy: 0.9507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ffd673e970>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_robust.fit(X_train, y_train, batch_size=10, validation_data=(X_test0, y_test0), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_original = KerasClassifier(original_model, clip_values=(0, 1), use_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_classifier = KerasClassifier(model_robust, clip_values=(0, 1), use_logits=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precompute adv samples: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 1/1 [00:00<?, ?it/s]\n",
      "Adversarial training epochs:   0%|                                                               | 0/2 [00:00<?, ?it/s]C:\\Users\\diana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n",
      "Adversarial training epochs: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââ| 2/2 [35:36<00:00, 1068.12s/it]\n"
     ]
    }
   ],
   "source": [
    "attacks = BasicIterativeMethod(robust_classifier, eps=60, eps_step=2, max_iter=40)\n",
    "trainer = AdversarialTrainer(robust_classifier, attacks, ratio=1.0)\n",
    "trainer.fit(X_train, y_train, nb_epochs=2, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClasificaciÃ³n del dataset original para el modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data (1401 images):\n",
      "Correctly classified: 1356\n",
      "Incorrectly classified: 45\n"
     ]
    }
   ],
   "source": [
    "x_test_pred = np.argmax(classifier_original.predict(X_test0), axis=1)\n",
    "nb_correct_pred = np.sum(x_test_pred == np.argmax(y_test0, axis=1))\n",
    "\n",
    "print(\"Original test data ({} images):\".format(len(X_test0)))\n",
    "print(\"Correctly classified: {}\".format(nb_correct_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(X_test0) - nb_correct_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver segun los resultados que unicamente el 3.85% de los datos fueron seleccionados incorrectamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClasificaciÃ³n de dataset con ataque de FGM para el modelo original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker = FastGradientMethod(classifier_original, eps=100)\n",
    "x_test_adv = attacker.generate(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data (1401 images):\n",
      "Correctly classified: 160\n",
      "Incorrectly classified: 1241\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_pred = np.argmax(classifier_original.predict(x_test_adv), axis=1)\n",
    "nb_correct_adv_pred = np.sum(x_test_adv_pred == np.argmax(y_test0, axis=1))\n",
    "\n",
    "print(\"Adversarial test data ({} images):\".format(len(X_test0)))\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(X_test0) - nb_correct_adv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede ver segun los resultados que despues del ataque unicamente el 2.21% de los datos fueron seleccionados correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClasificaciÃ³n de dataset original para modelo robusto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original test data (1401 images):\n",
      "Correctly classified: 1132\n",
      "Incorrectly classified: 269\n"
     ]
    }
   ],
   "source": [
    "x_test_robust_pred = np.argmax(robust_classifier.predict(X_test0), axis=1)\n",
    "nb_correct_robust_pred = np.sum(x_test_robust_pred == np.argmax(y_test0, axis=1))\n",
    "\n",
    "print(\"Original test data ({} images):\".format(len(X_test0)))\n",
    "print(\"Correctly classified: {}\".format(nb_correct_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(X_test0) - nb_correct_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClasificaciÃ³n de dataset con FGM para modelo robusto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuevo modelo robusto responde mejor que el anterior a los ataques ya aproximadamente el 90% de los datos se clasificaron bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacker_robust = FastGradientMethod(robust_classifier, eps=100)\n",
    "x_test_adv_robust = attacker_robust.generate(X_test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial test data (1401 images):\n",
      "Correctly classified: 941\n",
      "Incorrectly classified: 460\n"
     ]
    }
   ],
   "source": [
    "x_test_adv_robust_pred = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "nb_correct_adv_robust_pred = np.sum(x_test_adv_robust_pred == np.argmax(y_test0, axis=1))\n",
    "\n",
    "print(\"Adversarial test data ({} images):\".format(len(X_test0)))\n",
    "print(\"Correctly classified: {}\".format(nb_correct_adv_robust_pred))\n",
    "print(\"Incorrectly classified: {}\".format(len(X_test0) - nb_correct_adv_robust_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El nuevo modelo robusto responde mejor que el anterior a los ataques ya aproximadamente el 90% de los datos se clasificaron bien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados de modelo original y robusto ante FGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_range = [1, 2, 3, 4, 5, 10, 30, 30, 40, 50, 60, 70, 80, 90]\n",
    "nb_correct_original = []\n",
    "nb_correct_robust = []\n",
    "\n",
    "for eps in eps_range:\n",
    "    attacker.set_params(**{'eps': eps})\n",
    "    attacker_robust.set_params(**{'eps': eps})\n",
    "    x_test_adv = attacker.generate(X_test0)\n",
    "    x_test_adv_robust = attacker_robust.generate(X_test0)\n",
    "    \n",
    "    x_test_adv_pred = np.argmax(classifier_original.predict(x_test_adv), axis=1)\n",
    "    nb_correct_original += [np.sum(x_test_adv_pred == np.argmax(y_test0, axis=1))]\n",
    "    \n",
    "    x_test_adv_robust_pred = np.argmax(robust_classifier.predict(x_test_adv_robust), axis=1)\n",
    "    nb_correct_robust += [np.sum(x_test_adv_robust_pred == np.argmax(y_test0, axis=1))]\n",
    "\n",
    "eps_range = [0] + eps_range\n",
    "nb_correct_original = [nb_correct_pred] + nb_correct_original\n",
    "nb_correct_robust = [nb_correct_robust_pred] + nb_correct_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1356,\n",
       " 1356,\n",
       " 1356,\n",
       " 1356,\n",
       " 1356,\n",
       " 1357,\n",
       " 1357,\n",
       " 1324,\n",
       " 1324,\n",
       " 1284,\n",
       " 1207,\n",
       " 995,\n",
       " 696,\n",
       " 367,\n",
       " 186]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_correct_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1132,\n",
       " 1253,\n",
       " 1257,\n",
       " 1260,\n",
       " 1264,\n",
       " 1265,\n",
       " 1282,\n",
       " 1344,\n",
       " 1344,\n",
       " 1351,\n",
       " 1357,\n",
       " 1355,\n",
       " 1346,\n",
       " 1315,\n",
       " 1193]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_correct_robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.array(eps_range), np.array(nb_correct_original), 'b--', label='Original classifier')\n",
    "ax.plot(np.array(eps_range), np.array(nb_correct_robust), 'r--', label='Robust classifier')\n",
    "\n",
    "legend = ax.legend(loc='upper center', shadow=True, fontsize='large')\n",
    "legend.get_frame().set_facecolor('#00FFCC')\n",
    "\n",
    "plt.xlabel('Attack strength (eps)')\n",
    "plt.ylabel('Correct predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta grafica se observa claramente que el clasificador robusto, presentÃ³ un desempeÃ±o muchÃ­simo mejor que el del clasificador orignal. Es importante mencionar que el desempeÃ±o del clasificador original fue descendente mientras que el del clasificador robusto fue ascendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_malware_robust-parte2.h5']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(robust_classifier, 'model_malware_robust-parte2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
